{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "yoga_classification_training.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FTlrCcjIm2e"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing import sequence\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GRerErQWhO4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d09fd653-769b-4cff-897f-c4f236e3fd50"
      },
      "source": [
        "# final model\n",
        "base_model = tf.keras.applications.MobileNetV2(input_shape=(640,640,3),include_top=False,weights='imagenet')\n",
        "model = tf.keras.Sequential([\n",
        "                             base_model,\n",
        "                             tf.keras.layers.BatchNormalization(),\n",
        "                             tf.keras.layers.GlobalAveragePooling2D(),\n",
        "                             tf.keras.layers.Dense(14),\n",
        "                             tf.keras.layers.Activation('softmax')\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 20, 20, 1280)     2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 20, 1280)     5120      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                17934     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,281,038\n",
            "Trainable params: 2,244,366\n",
            "Non-trainable params: 36,672\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2wVqhfHVdne",
        "outputId": "ea81c3e6-1475-482e-e747-b49e4ecfb54d"
      },
      "source": [
        "model.load_weights('/content/drive/MyDrive/LG/train_ckpt_1/ckpt_16')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f869bf04ed0>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdRsuxoUJJM3"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=50, decay_rate=0.96, staircase=False\n",
        ")\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=initial_learning_rate), loss=loss,metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7pJq7VJM3R7",
        "outputId": "44a1c640-34ae-4de0-e192-2924b47023aa"
      },
      "source": [
        "model.save('/content/drive/MyDrive/LG/classification.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  category=CustomMaskWarning)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lILNSWzpM_Ur"
      },
      "source": [
        "model.load()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qafVwrEWILU0",
        "outputId": "e675b365-ec9d-43ee-aded-72650402eccf"
      },
      "source": [
        "model.evaluate(normalized_ds_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 8s 615ms/step - loss: 0.1615 - accuracy: 0.9529\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.16147038340568542, 0.9528985619544983]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7jYz8IYORaF"
      },
      "source": [
        "batch_size = 16\n",
        "IMG_SIZE = (640,640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXLw9aiucjbl",
        "outputId": "35f4a5a0-d435-4cee-dcda-c3b813e76458"
      },
      "source": [
        "# import os\n",
        "# import cv2\n",
        "\n",
        "# def check_images( s_dir, ext_list):\n",
        "#     bad_images=[]\n",
        "#     bad_ext=[]\n",
        "#     s_list= os.listdir(s_dir)\n",
        "#     for klass in s_list:\n",
        "#         klass_path=os.path.join (s_dir, klass)\n",
        "#         print ('processing class directory ', klass)\n",
        "#         if os.path.isdir(klass_path):\n",
        "#             file_list=os.listdir(klass_path)\n",
        "#             for f in file_list:\n",
        "#                 f_path=os.path.join (klass_path,f)\n",
        "#                 index=f.rfind('.')\n",
        "#                 ext=f[index+1:].lower()\n",
        "#                 if ext not in ext_list:\n",
        "#                     print('file ', f_path, ' has an invalid extension ', ext)\n",
        "#                     bad_ext.append(f_path)\n",
        "#                 if os.path.isfile(f_path):\n",
        "#                     try:\n",
        "#                         img=cv2.imread(f_path)\n",
        "#                         shape=img.shape\n",
        "#                     except:\n",
        "#                         print('file ', f_path, ' is not a valid image file')\n",
        "#                         bad_images.append(f_path)\n",
        "#                 else:\n",
        "#                     print('*** fatal error, you a sub directory ', f, ' in class directory ', klass)\n",
        "#         else:\n",
        "#             print ('*** WARNING*** you have files in ', s_dir, ' it should only contain sub directories')\n",
        "#     return bad_images, bad_ext\n",
        "\n",
        "# source_dir ='Yoga_dataset/TRAIN'\n",
        "# good_exts=['jpg', 'png', 'jpeg', 'gif', 'bmp' ] # list of acceptable extensions\n",
        "# bad_file_list, bad_ext_list=check_images(source_dir, good_exts)\n",
        "# if len(bad_file_list) !=0:\n",
        "#     print('improper image files are listed below')\n",
        "#     for i in range (len(bad_file_list)):\n",
        "#         print (bad_file_list[i])\n",
        "#         os.remove(bad_file_list[i])\n",
        "# if len(bad_ext_list) !=0:\n",
        "#     print('improper image files are listed below')\n",
        "#     for i in range (len(bad_ext_list)):\n",
        "#         print (bad_ext_list[i])\n",
        "#         os.remove(bad_ext_list[i])\n",
        "# else:\n",
        "#     print(' no improper image files were found')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "processing class directory  plank\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/00000337.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/00000424.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_3.png  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_4.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_29.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_33.gif  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_32.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_37.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_39.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_40.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_41.jpeg  is not a valid image file\n",
            "file  /content/drive/MyDrive/LG/TRAIN/plank/Image_53.jpeg  is not a valid image file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzVA6aMt-qde"
      },
      "source": [
        "batch_size = 16\n",
        "IMG_SIZE = (640,640)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJpF-4kdQYN9",
        "outputId": "de51728b-a919-4b12-f6ff-f379a925ca9a"
      },
      "source": [
        "data_dir = '/content/drive/MyDrive/LG/fine'\n",
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"training\",\n",
        "  seed=123,\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1785 files belonging to 14 classes.\n",
            "Using 1607 files for training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jw7tJDoyR3LV",
        "outputId": "0dd845c4-1c1c-447e-eb62-be3a9234f5e5"
      },
      "source": [
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  data_dir,\n",
        "  validation_split=0.1,\n",
        "  subset=\"validation\",\n",
        "  seed=123,\n",
        "  image_size=IMG_SIZE,\n",
        "  batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1785 files belonging to 14 classes.\n",
            "Using 178 files for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ksS1JT8-R_uI",
        "outputId": "c8f130c5-8817-43b1-804f-60e421e175be"
      },
      "source": [
        "train_ds.class_names"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Triangle',\n",
              " 'cobra1',\n",
              " 'cobra2',\n",
              " 'downdog',\n",
              " 'goddess1',\n",
              " 'goddess2',\n",
              " 'plank1',\n",
              " 'plank2',\n",
              " 'plank3',\n",
              " 'plank4',\n",
              " 'tree1',\n",
              " 'tree2',\n",
              " 'tree4',\n",
              " 'warrior2']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sgar9y_TEQr"
      },
      "source": [
        "data_augmentation = tf.keras.Sequential([\n",
        "  tf.keras.layers.RandomFlip(\"horizontal\"),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2upZKA8cXNyx",
        "outputId": "60f6852b-23a0-47aa-8d08-6e15b53438f2"
      },
      "source": [
        "normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)\n",
        "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "normalized_ds_val = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "image_batch, labels_batch = next(iter(normalized_ds))\n",
        "first_image = image_batch[0]\n",
        "# Notice the pixels values are now in `[0,1]`.\n",
        "print(np.min(first_image), np.max(first_image))\n",
        "print(\"Normalization done\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.01796288 1.0\n",
            "Normalization done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwaFxWU2XhRQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b78b5cd9-5cc5-41d8-8d7e-99e5ddec097b"
      },
      "source": [
        "model.summary() #window claffier "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " mobilenetv2_1.00_224 (Funct  (None, 20, 20, 1280)     2257984   \n",
            " ional)                                                          \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 20, 20, 1280)     5120      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " global_average_pooling2d_1   (None, 1280)             0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 14)                17934     \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 14)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,281,038\n",
            "Trainable params: 2,244,366\n",
            "Non-trainable params: 36,672\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRAtDgxU_BeC"
      },
      "source": [
        "initial_learning_rate = 0.01\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate, decay_steps=50, decay_rate=0.96, staircase=False\n",
        ")\n",
        "def loss(labels, logits):\n",
        "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits)\n",
        "model.compile(optimizer=tf.keras.optimizers.SGD(learning_rate=initial_learning_rate), loss=loss,metrics='accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UwZAPGD_m4T"
      },
      "source": [
        "import datetime\n",
        "import os\n",
        "checkpoint_dir = '/content/drive/MyDrive/LG/classf_log'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "#logdir = os.path.join(\"/content/drive/MyDrive/multicrop_logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "#tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "early_stopping_cb = tf.keras.callbacks.EarlyStopping(\n",
        "    patience=10, restore_best_weights=True\n",
        ")\n",
        "\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True,verbose=2,\n",
        "    save_best_only=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjgc73F9_zBY",
        "outputId": "27440d29-42e3-4ba6-f11a-b8fd804a1e31"
      },
      "source": [
        "history = model.fit(normalized_ds,epochs=30,\n",
        "                    validation_data=normalized_ds_val,callbacks=[checkpoint_callback,early_stopping_cb])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 2.0143 - accuracy: 0.4082\n",
            "Epoch 00001: val_loss improved from inf to 2.00719, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_1\n",
            "101/101 [==============================] - 260s 2s/step - loss: 2.0143 - accuracy: 0.4082 - val_loss: 2.0072 - val_accuracy: 0.3371\n",
            "Epoch 2/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.9402 - accuracy: 0.7754\n",
            "Epoch 00002: val_loss improved from 2.00719 to 1.72687, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_2\n",
            "101/101 [==============================] - 165s 2s/step - loss: 0.9402 - accuracy: 0.7754 - val_loss: 1.7269 - val_accuracy: 0.4270\n",
            "Epoch 3/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.5236 - accuracy: 0.8749\n",
            "Epoch 00003: val_loss improved from 1.72687 to 1.50218, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_3\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.5236 - accuracy: 0.8749 - val_loss: 1.5022 - val_accuracy: 0.4719\n",
            "Epoch 4/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.3394 - accuracy: 0.9266\n",
            "Epoch 00004: val_loss improved from 1.50218 to 1.15129, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_4\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.3394 - accuracy: 0.9266 - val_loss: 1.1513 - val_accuracy: 0.6011\n",
            "Epoch 5/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.2502 - accuracy: 0.9465\n",
            "Epoch 00005: val_loss improved from 1.15129 to 0.87082, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_5\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.2502 - accuracy: 0.9465 - val_loss: 0.8708 - val_accuracy: 0.7022\n",
            "Epoch 6/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.1811 - accuracy: 0.9664\n",
            "Epoch 00006: val_loss improved from 0.87082 to 0.72618, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_6\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.1811 - accuracy: 0.9664 - val_loss: 0.7262 - val_accuracy: 0.8090\n",
            "Epoch 7/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.1419 - accuracy: 0.9770\n",
            "Epoch 00007: val_loss improved from 0.72618 to 0.63175, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_7\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.1419 - accuracy: 0.9770 - val_loss: 0.6317 - val_accuracy: 0.8090\n",
            "Epoch 8/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.1166 - accuracy: 0.9863\n",
            "Epoch 00008: val_loss improved from 0.63175 to 0.48101, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_8\n",
            "101/101 [==============================] - 165s 2s/step - loss: 0.1166 - accuracy: 0.9863 - val_loss: 0.4810 - val_accuracy: 0.8708\n",
            "Epoch 9/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0891 - accuracy: 0.9913\n",
            "Epoch 00009: val_loss improved from 0.48101 to 0.38922, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_9\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0891 - accuracy: 0.9913 - val_loss: 0.3892 - val_accuracy: 0.9045\n",
            "Epoch 10/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0699 - accuracy: 0.9944\n",
            "Epoch 00010: val_loss improved from 0.38922 to 0.31905, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_10\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0699 - accuracy: 0.9944 - val_loss: 0.3191 - val_accuracy: 0.9382\n",
            "Epoch 11/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9975\n",
            "Epoch 00011: val_loss improved from 0.31905 to 0.29362, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_11\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0646 - accuracy: 0.9975 - val_loss: 0.2936 - val_accuracy: 0.9382\n",
            "Epoch 12/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9988\n",
            "Epoch 00012: val_loss improved from 0.29362 to 0.23965, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_12\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0475 - accuracy: 0.9988 - val_loss: 0.2397 - val_accuracy: 0.9494\n",
            "Epoch 13/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0439 - accuracy: 0.9956\n",
            "Epoch 00013: val_loss improved from 0.23965 to 0.23103, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_13\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0439 - accuracy: 0.9956 - val_loss: 0.2310 - val_accuracy: 0.9438\n",
            "Epoch 14/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9975\n",
            "Epoch 00014: val_loss improved from 0.23103 to 0.22876, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_14\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0382 - accuracy: 0.9975 - val_loss: 0.2288 - val_accuracy: 0.9551\n",
            "Epoch 15/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9975\n",
            "Epoch 00015: val_loss improved from 0.22876 to 0.21380, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_15\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0359 - accuracy: 0.9975 - val_loss: 0.2138 - val_accuracy: 0.9494\n",
            "Epoch 16/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9988\n",
            "Epoch 00016: val_loss improved from 0.21380 to 0.17511, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_16\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0270 - accuracy: 0.9988 - val_loss: 0.1751 - val_accuracy: 0.9607\n",
            "Epoch 17/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0322 - accuracy: 0.9975\n",
            "Epoch 00017: val_loss improved from 0.17511 to 0.15925, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_17\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0322 - accuracy: 0.9975 - val_loss: 0.1592 - val_accuracy: 0.9607\n",
            "Epoch 18/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0263 - accuracy: 1.0000\n",
            "Epoch 00018: val_loss did not improve from 0.15925\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0263 - accuracy: 1.0000 - val_loss: 0.1820 - val_accuracy: 0.9607\n",
            "Epoch 19/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9975\n",
            "Epoch 00019: val_loss improved from 0.15925 to 0.15612, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_19\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0276 - accuracy: 0.9975 - val_loss: 0.1561 - val_accuracy: 0.9607\n",
            "Epoch 20/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9988\n",
            "Epoch 00020: val_loss improved from 0.15612 to 0.14506, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_20\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0247 - accuracy: 0.9988 - val_loss: 0.1451 - val_accuracy: 0.9663\n",
            "Epoch 21/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9994\n",
            "Epoch 00021: val_loss improved from 0.14506 to 0.14445, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_21\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0197 - accuracy: 0.9994 - val_loss: 0.1445 - val_accuracy: 0.9663\n",
            "Epoch 22/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9988\n",
            "Epoch 00022: val_loss improved from 0.14445 to 0.13026, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_22\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0170 - accuracy: 0.9988 - val_loss: 0.1303 - val_accuracy: 0.9719\n",
            "Epoch 23/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9988\n",
            "Epoch 00023: val_loss improved from 0.13026 to 0.12998, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_23\n",
            "101/101 [==============================] - 167s 2s/step - loss: 0.0194 - accuracy: 0.9988 - val_loss: 0.1300 - val_accuracy: 0.9775\n",
            "Epoch 24/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9988\n",
            "Epoch 00024: val_loss improved from 0.12998 to 0.11863, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_24\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0170 - accuracy: 0.9988 - val_loss: 0.1186 - val_accuracy: 0.9607\n",
            "Epoch 25/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 1.0000\n",
            "Epoch 00025: val_loss did not improve from 0.11863\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0140 - accuracy: 1.0000 - val_loss: 0.1258 - val_accuracy: 0.9719\n",
            "Epoch 26/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0120 - accuracy: 0.9994\n",
            "Epoch 00026: val_loss did not improve from 0.11863\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0120 - accuracy: 0.9994 - val_loss: 0.1195 - val_accuracy: 0.9775\n",
            "Epoch 27/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0114 - accuracy: 0.9994\n",
            "Epoch 00027: val_loss did not improve from 0.11863\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0114 - accuracy: 0.9994 - val_loss: 0.1276 - val_accuracy: 0.9775\n",
            "Epoch 28/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0136 - accuracy: 0.9994\n",
            "Epoch 00028: val_loss did not improve from 0.11863\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0136 - accuracy: 0.9994 - val_loss: 0.1308 - val_accuracy: 0.9719\n",
            "Epoch 29/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0139 - accuracy: 0.9988\n",
            "Epoch 00029: val_loss did not improve from 0.11863\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0139 - accuracy: 0.9988 - val_loss: 0.1216 - val_accuracy: 0.9719\n",
            "Epoch 30/30\n",
            "101/101 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 1.0000\n",
            "Epoch 00030: val_loss improved from 0.11863 to 0.11739, saving model to /content/drive/MyDrive/LG/classf_log/ckpt_30\n",
            "101/101 [==============================] - 166s 2s/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 0.1174 - val_accuracy: 0.9775\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIWG7QtM_3oP",
        "outputId": "5ce83b1a-5730-4aa3-b04b-80b02937216b"
      },
      "source": [
        "model.save('/content/drive/MyDrive/LG/classification2.h5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqGLYhwZVh1K"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}